{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QD_Z_9mesh4T"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading dataset\n",
        "df = pd.read_csv('dataset1.csv')\n",
        "\n",
        "# Preparing data\n",
        "X = df[['Hours']]  # Features\n",
        "y = df['SuccessRate']  # Target variable\n",
        "\n",
        "# Spliting dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "FppWCmvc08VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7RSydT9g4-Jf",
        "outputId": "d469cbdd-1356-49e3-dfe8-bca6de9c6a3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Hours  SuccessRate\n",
              "0    0.0         20.0\n",
              "1    0.2         21.6\n",
              "2    0.4         23.2\n",
              "3    0.6         24.8\n",
              "4    0.8         26.4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34ca8001-0f61-49cd-874a-3682f974345c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hours</th>\n",
              "      <th>SuccessRate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.2</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.4</td>\n",
              "      <td>23.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.6</td>\n",
              "      <td>24.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.8</td>\n",
              "      <td>26.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34ca8001-0f61-49cd-874a-3682f974345c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-34ca8001-0f61-49cd-874a-3682f974345c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-34ca8001-0f61-49cd-874a-3682f974345c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-72a8ca2c-87ca-4b5d-9cd3-122f61830887\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-72a8ca2c-87ca-4b5d-9cd3-122f61830887')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-72a8ca2c-87ca-4b5d-9cd3-122f61830887 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model =  tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units = 32, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(units = 1, activation = \"relu\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss = tf.keras.losses.mae,\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3),\n",
        "    metrics = [\"mae\"]\n",
        ")\n",
        "\n",
        "model.fit(X_train,y_train, batch_size=1, epochs = 30, verbose = 2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndkd21vP84ih",
        "outputId": "c9734df8-58a8-47c1-9ec3-2c8b4b3cd978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "40/40 - 1s - loss: 57.2400 - mae: 57.2400 - 576ms/epoch - 14ms/step\n",
            "Epoch 2/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 52ms/epoch - 1ms/step\n",
            "Epoch 3/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 52ms/epoch - 1ms/step\n",
            "Epoch 4/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 52ms/epoch - 1ms/step\n",
            "Epoch 5/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 54ms/epoch - 1ms/step\n",
            "Epoch 6/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 53ms/epoch - 1ms/step\n",
            "Epoch 7/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 56ms/epoch - 1ms/step\n",
            "Epoch 8/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 51ms/epoch - 1ms/step\n",
            "Epoch 9/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 60ms/epoch - 2ms/step\n",
            "Epoch 10/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 59ms/epoch - 1ms/step\n",
            "Epoch 11/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 52ms/epoch - 1ms/step\n",
            "Epoch 12/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 53ms/epoch - 1ms/step\n",
            "Epoch 13/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 54ms/epoch - 1ms/step\n",
            "Epoch 14/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 67ms/epoch - 2ms/step\n",
            "Epoch 15/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 81ms/epoch - 2ms/step\n",
            "Epoch 16/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 84ms/epoch - 2ms/step\n",
            "Epoch 17/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 77ms/epoch - 2ms/step\n",
            "Epoch 18/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 77ms/epoch - 2ms/step\n",
            "Epoch 19/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 81ms/epoch - 2ms/step\n",
            "Epoch 20/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 80ms/epoch - 2ms/step\n",
            "Epoch 21/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 76ms/epoch - 2ms/step\n",
            "Epoch 22/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 76ms/epoch - 2ms/step\n",
            "Epoch 23/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 77ms/epoch - 2ms/step\n",
            "Epoch 24/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 73ms/epoch - 2ms/step\n",
            "Epoch 25/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 71ms/epoch - 2ms/step\n",
            "Epoch 26/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 80ms/epoch - 2ms/step\n",
            "Epoch 27/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 73ms/epoch - 2ms/step\n",
            "Epoch 28/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 84ms/epoch - 2ms/step\n",
            "Epoch 29/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 84ms/epoch - 2ms/step\n",
            "Epoch 30/30\n",
            "40/40 - 0s - loss: 57.2400 - mae: 57.2400 - 67ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78b9118c7e20>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5kj7m539B98",
        "outputId": "4ed5e6d2-b5d0-4280-ae80-91e2bb89a9b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_224\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_448 (Dense)           (1, 32)                   64        \n",
            "                                                                 \n",
            " dense_449 (Dense)           (1, 1)                    33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 97 (388.00 Byte)\n",
            "Trainable params: 97 (388.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = model.predict(X_test)\n",
        "y_preds"
      ],
      "metadata": {
        "id": "A4kxxmax9Gj0",
        "outputId": "27466583-206c-44a6-ea30-578add92927e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "results=[]\n",
        "# Define the hyperparameters\n",
        "epochs_list = [20, 30]\n",
        "learning_rates = [0.001, 0.01]\n",
        "neurons_list = [128, 64]\n",
        "batch_sizes = [32, 64]\n",
        "optimizers = ['SGD', 'Adam']\n",
        "\n",
        "# Loop over the hyperparameters\n",
        "for epochs in epochs_list:\n",
        "    for lr in learning_rates:\n",
        "        for neurons in neurons_list:\n",
        "            for batch_size in batch_sizes:\n",
        "                for optimizer_name in optimizers:\n",
        "                    print(f\"Training with epochs: {epochs}, learning rate: {lr}, neurons: {neurons}, batch size: {batch_size}, optimizer: {optimizer_name}\")\n",
        "\n",
        "                    # Define model\n",
        "                    model_nn = Sequential([\n",
        "                        Dense(neurons, input_dim=1, activation='relu'),\n",
        "                        Dense(1, activation='linear')\n",
        "                    ])\n",
        "\n",
        "                    # Choose optimizer\n",
        "                    if optimizer_name == 'SGD':\n",
        "                        optimizer = SGD(learning_rate=lr)\n",
        "                    elif optimizer_name == 'Adam':\n",
        "                        optimizer = Adam(learning_rate=lr)\n",
        "\n",
        "                    # Compile model\n",
        "                    model_nn.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "                    es= EarlyStopping(monitor='mean_squared_error',mode='min',verbose=1)\n",
        "\n",
        "                    # Train the model\n",
        "                    model_nn.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "                    # Evaluate the model on the test data\n",
        "                    loss = model_nn.evaluate(X_test, y_test, verbose=0)\n",
        "                    print(f\"Test Loss: {loss/100}\\n\")\n",
        "                    results.append((epochs, lr, neurons, batch_size, optimizer_name, loss))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxO_MIfH2aUP",
        "outputId": "87a400c5-5d96-44e7-a2b6-b182380cb0fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with epochs: 20, learning rate: 0.001, neurons: 128, batch size: 32, optimizer: SGD\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3535.4500\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1242.4686\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 97.9329\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 94.0885\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 95.3170\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 89.8898\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 86.8075\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 86.6731\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 90.6763\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 90.6989\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 77.1995\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 79.2133\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 74.6148\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 78.6311\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 92.4499\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 83.5444\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 76.6259\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 74.4334\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 64.3613\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 70.5126\n",
            "Test Loss: 0.28401830673217776\n",
            "\n",
            "Training with epochs: 20, learning rate: 0.001, neurons: 128, batch size: 32, optimizer: Adam\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3722.7280\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3702.6121\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3680.8098\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3660.4797\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3638.6152\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3617.7583\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3597.0195\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3574.9172\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3553.1426\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3532.1704\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3511.4155\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3489.5073\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3468.7402\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3447.9165\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3427.4160\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3406.3198\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3385.0664\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3364.8262\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3343.5767\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3322.6147\n",
            "Test Loss: 41.229228515625\n",
            "\n",
            "Training with epochs: 20, learning rate: 0.001, neurons: 128, batch size: 64, optimizer: SGD\n",
            "Epoch 1/20\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 3824.0474\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3275.0427\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2409.6394\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1018.2012\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 131.7793\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 96.6945\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 93.1882\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 91.6015\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 90.3337\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 89.1189\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 87.9247\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 86.7465\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 85.5834\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 84.4347\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 83.3002\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 82.1796\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 81.0724\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 79.9785\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 78.8974\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 77.8289\n",
            "Test Loss: 0.3379015350341797\n",
            "\n",
            "Training with epochs: 20, learning rate: 0.001, neurons: 128, batch size: 64, optimizer: Adam\n",
            "Epoch 1/20\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 3712.0793\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3702.4011\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3692.7437\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3683.1360\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3673.6321\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3664.1226\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3654.6082\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3645.0874\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3635.5586\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3626.0220\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3616.4819\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3606.9351\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3597.3735\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3587.7954\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3578.2026\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3568.6055\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3559.0508\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3549.4915\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3539.9087\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3530.2944\n",
            "Test Loss: 44.008740234375\n",
            "\n",
            "Training with epochs: 20, learning rate: 0.001, neurons: 64, batch size: 32, optimizer: SGD\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3768.2637\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2210.9385\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 114.9070\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 95.5381\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 99.9622\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 114.6367\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 87.2332\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 91.4766\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 118.4211\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 81.0314\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 84.1401\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 77.2904\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 77.1370\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 74.7551\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 69.8089\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 75.1484\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 67.8891\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 67.8887\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 65.6204\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 61.1282\n",
            "Test Loss: 0.26476306915283204\n",
            "\n",
            "Training with epochs: 20, learning rate: 0.001, neurons: 64, batch size: 32, optimizer: Adam\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 1s 8ms/step - loss: 3569.5435\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3555.8645\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3541.8828\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3527.7446\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3514.2168\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3500.7446\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3487.1997\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3473.5679\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3460.1895\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3446.0825\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3432.6870\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3418.3464\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3404.9204\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3390.1978\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3375.7500\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3362.1118\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3347.2610\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3332.2715\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3318.0383\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3303.1567\n",
            "Test Loss: 41.0459375\n",
            "\n",
            "Training with epochs: 20, learning rate: 0.001, neurons: 64, batch size: 64, optimizer: SGD\n",
            "Epoch 1/20\n",
            "1/1 [==============================] - 0s 416ms/step - loss: 3928.6887\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3184.5540\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2213.4675\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 798.4415\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 104.4422\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 94.9152\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 92.8646\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 91.5085\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 90.2688\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 89.0578\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 87.8642\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 86.6861\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 85.5229\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 84.3742\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 83.2396\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 82.1185\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 81.0108\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 79.9163\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 78.8347\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 77.7656\n",
            "Test Loss: 0.33763111114501954\n",
            "\n",
            "Training with epochs: 20, learning rate: 0.001, neurons: 64, batch size: 64, optimizer: Adam\n",
            "Epoch 1/20\n",
            "1/1 [==============================] - 1s 625ms/step - loss: 3834.8438\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3828.7156\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3822.5891\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3816.4648\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3810.3430\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3804.2222\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3798.1030\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3791.9844\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3785.8672\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3779.7520\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3773.6431\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3767.5664\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3761.6011\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3755.6375\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3749.6685\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3743.6929\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3737.7109\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3731.7212\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3725.7231\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3719.7161\n",
            "Test Loss: 46.485244140625\n",
            "\n",
            "Training with epochs: 20, learning rate: 0.01, neurons: 128, batch size: 32, optimizer: SGD\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 1s 13ms/step - loss: 5375.8262\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 3927.1094\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 3675.5515\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3436.8242\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 3208.3708\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 3005.0210\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2795.7310\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2632.1091\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2474.1035\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2334.8208\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 2198.6472\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2064.9365\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1943.8828\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1830.7787\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1732.1615\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1634.1656\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1543.5558\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1468.1735\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1398.6814\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1327.6921\n",
            "Test Loss: 16.45859130859375\n",
            "\n",
            "Training with epochs: 20, learning rate: 0.01, neurons: 128, batch size: 32, optimizer: Adam\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 1s 8ms/step - loss: 4020.6450\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3841.1348\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3677.6479\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3519.5176\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3370.1238\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3224.1968\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3073.9817\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2915.1135\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2741.7820\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2577.7974\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2386.1196\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2203.1340\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2000.9440\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1794.8406\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1589.2361\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1380.9479\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1174.1202\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 971.0844\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 776.7484\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 598.6143\n",
            "Test Loss: 5.305222778320313\n",
            "\n",
            "Training with epochs: 20, learning rate: 0.01, neurons: 128, batch size: 64, optimizer: SGD\n",
            "Epoch 1/20\n",
            "1/1 [==============================] - 0s 350ms/step - loss: 3766.3918\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10663.5967\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3902.8171\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3770.7253\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3643.8645\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3522.0269\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3405.0144\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3292.6355\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3184.7075\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3081.0527\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2981.5027\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2885.8950\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2794.0737\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2705.8882\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2621.1948\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2539.8552\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2461.7368\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2386.7117\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2314.6577\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2245.4570\n",
            "Test Loss: 28.1486572265625\n",
            "\n",
            "Training with epochs: 20, learning rate: 0.01, neurons: 128, batch size: 64, optimizer: Adam\n",
            "Epoch 1/20\n",
            "1/1 [==============================] - 1s 678ms/step - loss: 3843.7905\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3751.4199\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3662.4824\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3574.2727\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3486.5828\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3399.6711\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3311.7695\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3222.4548\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3131.5908\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3038.3828\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2942.7715\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2844.9827\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2744.3828\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2641.0872\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2534.9614\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2425.9326\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2314.1482\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2199.8110\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2083.1841\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1964.5980\n",
            "Test Loss: 22.69897705078125\n",
            "\n",
            "Training with epochs: 20, learning rate: 0.01, neurons: 64, batch size: 32, optimizer: SGD\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3940.1626\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3772.3594\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3523.2649\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3302.1594\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3077.3274\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2874.1780\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2685.7280\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2526.9419\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2389.3027\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2262.5938\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2123.6567\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2007.8252\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1895.3215\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1790.9177\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1692.3635\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1601.6238\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1521.5557\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1439.3488\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1371.3619\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1314.9281\n",
            "Test Loss: 16.302877197265627\n",
            "\n",
            "Training with epochs: 20, learning rate: 0.01, neurons: 64, batch size: 32, optimizer: Adam\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 1s 8ms/step - loss: 3765.3601\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3650.0586\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3547.5227\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3441.0024\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3324.4263\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3211.2527\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3090.8909\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2973.1226\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2837.6023\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2701.1147\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2563.2271\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2408.3599\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2249.9290\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2090.0913\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1923.3098\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1754.4258\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1582.9939\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1411.8336\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1245.9388\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1074.0078\n",
            "Test Loss: 11.27618408203125\n",
            "\n",
            "Training with epochs: 20, learning rate: 0.01, neurons: 64, batch size: 64, optimizer: SGD\n",
            "Epoch 1/20\n",
            "1/1 [==============================] - 0s 333ms/step - loss: 3678.0164\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 26139.0430\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4020.1367\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3883.3992\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3752.0767\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3625.9539\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3504.8254\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3388.4946\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3276.7695\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3169.4695\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3066.4182\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2967.4480\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2872.3970\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2781.1099\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2693.4375\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2609.2371\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2528.3711\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2450.7075\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2376.1194\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2304.4849\n",
            "Test Loss: 28.85274658203125\n",
            "\n",
            "Training with epochs: 20, learning rate: 0.01, neurons: 64, batch size: 64, optimizer: Adam\n",
            "Epoch 1/20\n",
            "1/1 [==============================] - 1s 502ms/step - loss: 3714.7734\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3635.0913\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3557.3218\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3479.5181\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3402.0828\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3324.9243\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3246.9585\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3168.0891\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3088.0549\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3006.6047\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2923.5154\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2838.6692\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2752.0234\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2663.5637\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2573.3042\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2481.2886\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2387.5874\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2292.3005\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2195.5537\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2097.5007\n",
            "Test Loss: 24.6258984375\n",
            "\n",
            "Training with epochs: 30, learning rate: 0.001, neurons: 128, batch size: 32, optimizer: SGD\n",
            "Epoch 1/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3609.4187\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1345.7529\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 96.0802\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 96.9877\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 90.8279\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 89.3867\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 86.3898\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 91.6439\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 81.3708\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 83.4086\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 92.4655\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 90.9241\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 80.7771\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 71.0752\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 68.4739\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 66.7536\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 71.8252\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 68.9830\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 67.3143\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 61.8865\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 64.8327\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 64.1570\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 54.8785\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 53.2039\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 51.4707\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 52.7523\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 48.8619\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 52.5128\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 50.0057\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 50.1324\n",
            "Test Loss: 0.26866741180419923\n",
            "\n",
            "Training with epochs: 30, learning rate: 0.001, neurons: 128, batch size: 32, optimizer: Adam\n",
            "Epoch 1/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3855.9512\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3833.6875\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3810.9993\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3789.7375\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3766.4719\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3745.3555\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3724.3801\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 3703.0320\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3681.6187\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3660.3450\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3640.6355\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3619.4949\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3598.2622\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3577.7480\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3556.3035\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3534.5593\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 3513.7954\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3492.5735\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3470.4341\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3448.2266\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3426.6555\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3404.6594\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3382.4382\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3359.3750\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3337.0559\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3316.0522\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3291.4102\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3269.6941\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3246.7214\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3223.2314\n",
            "Test Loss: 39.96030517578125\n",
            "\n",
            "Training with epochs: 30, learning rate: 0.001, neurons: 128, batch size: 64, optimizer: SGD\n",
            "Epoch 1/30\n",
            "1/1 [==============================] - 0s 334ms/step - loss: 3967.0149\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3094.7122\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2029.8597\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 624.1920\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 97.0181\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 94.9924\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 93.6360\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 92.3740\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 91.1392\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 89.9222\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 88.7210\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 87.5353\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 86.3645\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 85.2084\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 84.0665\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 82.9386\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 81.8243\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 80.7234\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 79.6354\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 78.5601\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 77.4972\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 76.4464\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 75.4074\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 74.3801\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 73.3641\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 72.3593\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 71.3655\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 70.3823\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 69.4097\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 68.4475\n",
            "Test Loss: 0.29746753692626954\n",
            "\n",
            "Training with epochs: 30, learning rate: 0.001, neurons: 128, batch size: 64, optimizer: Adam\n",
            "Epoch 1/30\n",
            "1/1 [==============================] - 1s 551ms/step - loss: 3765.6711\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3756.0171\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3746.3931\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3736.7681\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3727.1414\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3717.5117\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3707.8789\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3698.2415\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3688.5977\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3678.9458\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3669.2859\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3659.6179\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3649.9399\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3640.2507\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3630.5520\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3620.8481\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3611.1582\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3601.5261\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3591.8933\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3582.2891\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3572.7070\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3563.0984\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3553.4609\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3543.7937\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3534.0957\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3524.3657\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3514.6021\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3504.8062\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3494.9790\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3485.1274\n",
            "Test Loss: 43.433310546875\n",
            "\n",
            "Training with epochs: 30, learning rate: 0.001, neurons: 64, batch size: 32, optimizer: SGD\n",
            "Epoch 1/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3543.7310\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1268.8878\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 99.8677\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 94.0404\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 92.5069\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 98.1409\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 88.8137\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 97.0573\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 82.2402\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 79.3106\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 77.0826\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 74.7619\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 75.2977\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 77.2714\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 71.5920\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 67.8851\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 70.1716\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 66.8961\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 61.5629\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 60.0717\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 61.3599\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 56.4598\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 54.9576\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 57.8550\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 52.4335\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 50.4829\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 50.6158\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 48.0728\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 50.3092\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 44.3829\n",
            "Test Loss: 0.2341107940673828\n",
            "\n",
            "Training with epochs: 30, learning rate: 0.001, neurons: 64, batch size: 32, optimizer: Adam\n",
            "Epoch 1/30\n",
            "2/2 [==============================] - 1s 8ms/step - loss: 3998.5632\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3984.0796\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3969.0359\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3954.4075\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3940.1067\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3925.5652\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3910.8013\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3896.4946\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3882.2344\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3867.6899\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3853.7563\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3839.0657\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3825.6211\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3811.3530\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3797.3101\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3783.4856\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3769.1274\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3756.1790\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3741.8286\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3728.7876\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3714.8059\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3701.4121\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3687.8950\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3673.9460\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3660.5981\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3647.1062\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3633.3652\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3619.3562\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3605.5688\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3591.6882\n",
            "Test Loss: 44.787919921875\n",
            "\n",
            "Training with epochs: 30, learning rate: 0.001, neurons: 64, batch size: 64, optimizer: SGD\n",
            "Epoch 1/30\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 3962.5234\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3070.1357\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1992.7424\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 593.3627\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 96.0633\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 94.4790\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 93.1773\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 91.9253\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 90.6944\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 89.4804\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 88.2822\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 87.0993\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 85.9315\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 84.7783\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 83.6393\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 82.5142\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 81.4026\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 80.3043\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 79.2189\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 78.1462\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 77.0858\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 76.0375\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 75.0010\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 73.9761\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 72.9626\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 71.9601\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 70.9686\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 69.9878\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 69.0174\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 68.0574\n",
            "Test Loss: 0.29577495574951174\n",
            "\n",
            "Training with epochs: 30, learning rate: 0.001, neurons: 64, batch size: 64, optimizer: Adam\n",
            "Epoch 1/30\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 3900.0063\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3893.1875\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3886.3843\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3879.5984\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3872.8289\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3866.0767\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3859.3411\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3852.6226\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3845.9211\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3839.2375\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3832.5703\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3825.9219\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3819.2922\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3812.6831\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3806.1040\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3799.6060\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3793.1882\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3786.7808\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3780.3828\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3773.9946\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3767.6140\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3761.2407\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3754.8743\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3748.5132\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3742.1577\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3735.8066\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3729.4595\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3723.1147\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3716.7727\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3710.4316\n",
            "Test Loss: 46.368564453125\n",
            "\n",
            "Training with epochs: 30, learning rate: 0.01, neurons: 128, batch size: 32, optimizer: SGD\n",
            "Epoch 1/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3667.7312\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7562.3384\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3411.4375\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3194.9275\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2996.7881\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2817.8105\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2653.5427\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2498.8821\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2346.3687\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2203.2896\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2080.5088\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1972.6656\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1871.9847\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1776.4606\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1689.9788\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1604.1110\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1526.4285\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1456.6357\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1392.0339\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1332.1575\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1279.8738\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1226.8022\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1180.2424\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1141.4243\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1100.8044\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1057.6462\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1022.4873\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 992.0969\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 962.8723\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 937.0715\n",
            "Test Loss: 11.16839111328125\n",
            "\n",
            "Training with epochs: 30, learning rate: 0.01, neurons: 128, batch size: 32, optimizer: Adam\n",
            "Epoch 1/30\n",
            "2/2 [==============================] - 1s 8ms/step - loss: 3933.9458\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3728.7183\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3534.3203\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3352.5430\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3178.1848\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3000.9585\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2808.7131\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2616.9348\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2398.7200\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2188.2019\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1955.3522\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1717.9934\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1481.7092\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1253.8434\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1021.9245\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 801.7603\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 603.9031\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 440.4648\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 290.2106\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 181.9052\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 104.0975\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 59.2531\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 41.6999\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 42.8261\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 58.2779\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 75.8332\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 90.4513\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 99.2710\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 99.2596\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 91.6393\n",
            "Test Loss: 0.8338564300537109\n",
            "\n",
            "Training with epochs: 30, learning rate: 0.01, neurons: 128, batch size: 64, optimizer: SGD\n",
            "Epoch 1/30\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 3978.5344\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6642.8921\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3856.6841\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3726.4194\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3601.3130\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3481.1606\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3365.7664\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3254.9419\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3148.5059\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3046.2847\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2948.1118\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2853.8264\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2763.2744\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2676.3088\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2592.7866\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2512.5720\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2435.5342\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2361.5464\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2290.4893\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2222.2456\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2156.7046\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2093.7585\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2033.3057\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1975.2465\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1919.4863\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1865.9346\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1814.5035\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1765.1090\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1717.6705\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1672.1106\n",
            "Test Loss: 21.1581787109375\n",
            "\n",
            "Training with epochs: 30, learning rate: 0.01, neurons: 128, batch size: 64, optimizer: Adam\n",
            "Epoch 1/30\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 3845.6821\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3749.9875\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3658.3718\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3568.5168\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3479.9348\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3392.7212\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3305.6824\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3217.9380\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3128.7993\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3038.2231\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2945.9453\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2851.3313\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2754.2300\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2654.6519\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2552.4985\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2447.5581\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2339.8557\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2229.5747\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2116.9453\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2002.2582\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1885.8619\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1768.1644\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1649.6302\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1530.7738\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1412.1577\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1294.3882\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1178.1140\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1064.0193\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 952.8160\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 845.2367\n",
            "Test Loss: 8.760865478515624\n",
            "\n",
            "Training with epochs: 30, learning rate: 0.01, neurons: 64, batch size: 32, optimizer: SGD\n",
            "Epoch 1/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4426.2593\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3842.2593\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3573.8113\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3320.1992\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3084.0007\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2877.7632\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2710.1560\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2546.3159\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2393.5986\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2256.4985\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2123.3550\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1993.7201\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1879.3746\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1792.4407\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1694.5111\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1596.2217\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1509.2845\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1441.6726\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1379.0144\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1313.2965\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1259.4451\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1204.0686\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1164.1509\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1124.2166\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1079.3074\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1038.3879\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 997.7713\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 967.1416\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 934.0734\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 905.6720\n",
            "Test Loss: 10.8391259765625\n",
            "\n",
            "Training with epochs: 30, learning rate: 0.01, neurons: 64, batch size: 32, optimizer: Adam\n",
            "Epoch 1/30\n",
            "2/2 [==============================] - 1s 8ms/step - loss: 3941.6965\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3790.0405\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3658.9460\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3524.7773\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3405.5559\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3279.9968\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3158.1750\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3030.1865\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2897.3760\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2759.0249\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2617.7446\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2455.8879\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2301.9062\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2130.1216\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1957.3438\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1781.8180\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1603.7643\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1414.9971\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1231.5865\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1053.8706\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 894.4008\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 728.6415\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 582.2915\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 452.6620\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 340.4519\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 242.7283\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 170.2242\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 114.4414\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 74.9274\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 52.0460\n",
            "Test Loss: 0.185135498046875\n",
            "\n",
            "Training with epochs: 30, learning rate: 0.01, neurons: 64, batch size: 64, optimizer: SGD\n",
            "Epoch 1/30\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 4052.2441\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1468.7151\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3792.5215\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3643.5442\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3521.7192\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3404.7195\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3292.3521\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3184.4348\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3080.7908\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2981.2515\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2885.6538\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2793.8416\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2705.6653\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2620.9805\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2539.6497\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2461.5393\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2386.5220\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2314.4758\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2245.2820\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2178.8289\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2115.0071\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2053.7124\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1994.8455\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1938.3093\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1884.0120\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1831.8650\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1781.7828\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1733.6840\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1687.4899\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1643.1250\n",
            "Test Loss: 20.7955029296875\n",
            "\n",
            "Training with epochs: 30, learning rate: 0.01, neurons: 64, batch size: 64, optimizer: Adam\n",
            "Epoch 1/30\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 3646.6086\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3576.5698\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3508.9038\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3442.1758\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3375.6953\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3308.2954\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3239.7153\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3169.8743\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3098.6047\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3026.1931\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2952.2573\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2876.5344\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2799.0337\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2719.7690\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2638.7639\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2556.0542\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2471.6907\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2385.7412\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2298.2949\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2209.4575\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2119.3594\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2028.1527\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1936.0121\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1843.1328\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1749.7321\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1656.0511\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1562.3246\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1468.8141\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1375.8047\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1283.6039\n",
            "Test Loss: 14.45542236328125\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qp7JEBTi8ypT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(y_test, y_preds, color=\"blue\", label=\"model predictions\")\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='orange', label='y=x')\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.title(\"Model Predictions vs Actual Values\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "um4eqyJU2e_9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}